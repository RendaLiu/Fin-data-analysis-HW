# shareholder_performance_analyzer.py
"""
åŸºäºæŒè‚¡é‡‘é¢çš„è‚¡ä¸œæŠ•èµ„èƒ½åŠ›è¯„ä¼°
é€‚ç”¨äºåªæœ‰è‚¡ä¸œæŒè‚¡é‡‘é¢æ•°æ®çš„æƒ…å†µ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import scipy.stats as stats


class ShareholderAmountAnalyzer:
    """
    åŸºäºæŒè‚¡é‡‘é¢çš„è‚¡ä¸œæŠ•èµ„èƒ½åŠ›åˆ†æå™¨
    """
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
        plt.rcParams['axes.unicode_minus'] = False
        
        # å®šä¹‰è¯„åˆ†æƒé‡
        self.default_weights = {
            'portfolio_growth': 0.25,      # ç»„åˆå¢é•¿èƒ½åŠ›
            'stability_score': 0.20,       # æŠ•èµ„ç¨³å®šæ€§
            'concentration_score': 0.15,   # é›†ä¸­åº¦åˆç†æ€§
            'turnover_score': 0.15,        # æ¢æ‰‹ç‡åˆç†æ€§
            'consistency_score': 0.15,     # æŠ•èµ„ä¸€è‡´æ€§
            'size_score': 0.10            # è§„æ¨¡é€‚å½“æ€§
        }
    
    def normalize_stock_codes(self, df, code_column='ts_code'):
        """
        ç»Ÿä¸€è‚¡ç¥¨ä»£ç æ ¼å¼
        
        Parameters:
        df: åŒ…å«è‚¡ç¥¨ä»£ç çš„DataFrame
        code_column: è‚¡ç¥¨ä»£ç åˆ—å
        
        Returns:
        DataFrame: ç»Ÿä¸€æ ¼å¼åçš„æ•°æ®
        """
        print("ç»Ÿä¸€è‚¡ç¥¨ä»£ç æ ¼å¼...")
        
        df = df.copy()
        
        # å®šä¹‰è½¬æ¢å‡½æ•°
        def convert_code_format(code):
            if pd.isna(code):
                return code
            
            code_str = str(code).strip().upper()
            
            # å¤„ç† xxxxxx.SH/SZ æ ¼å¼ -> sh/sz.xxxxxx
            if '.' in code_str:
                parts = code_str.split('.')
                if len(parts) == 2:
                    stock_code = parts[0].zfill(6)  # è¡¥é½6ä½
                    exchange = parts[1].lower()     # è½¬å°å†™
                    return f"{exchange}.{stock_code}"
            
            # å¤„ç†å…¶ä»–æ ¼å¼ï¼ˆå¦‚æœæœ‰ï¼‰
            return code_str.lower()
    # åº”ç”¨è½¬æ¢
        df[code_column] = df[code_column].apply(convert_code_format)
        
        # ç»Ÿè®¡è½¬æ¢ç»“æœ
        unique_codes = df[code_column].nunique()
        sh_codes = df[df[code_column].str.startswith('sh.', na=False)][code_column].nunique()
        sz_codes = df[df[code_column].str.startswith('sz.', na=False)][code_column].nunique()
        
        print(f"è‚¡ç¥¨ä»£ç è½¬æ¢å®Œæˆ:")
        print(f"â€¢ æ€»è‚¡ç¥¨æ•°: {unique_codes}")
        print(f"â€¢ ä¸Šè¯è‚¡ç¥¨: {sh_codes}")
        print(f"â€¢ æ·±è¯è‚¡ç¥¨: {sz_codes}")
    
        return df

    def filter_exchanges_and_top_holders(self, df_holdings, daily_quarterly, top_n=200):
        """
        ç­›é€‰ä¸Šè¯æ·±è¯æ•°æ®å¹¶é€‰æ‹©å‰Nå¤§è‚¡ä¸œ
        
        Parameters:
        df_holdings: è‚¡ä¸œæŒè‚¡æ•°æ®
        daily_quarterly: å­£åº¦è‚¡ä»·æ•°æ®
        top_n: å‰Nå¤§è‚¡ä¸œ
        
        Returns:
        DataFrame: ç­›é€‰åçš„è‚¡ä¸œæ•°æ®
        """
        print(f"ç­›é€‰ä¸Šè¯æ·±è¯æ•°æ®å¹¶é€‰æ‹©å‰{top_n}å¤§è‚¡ä¸œ...")
        
        # 1. ç»Ÿä¸€è‚¡ç¥¨ä»£ç æ ¼å¼
        df_holdings_normalized = self.normalize_stock_codes(df_holdings, 'ts_code')
        
        # 2. ä»daily_quarterlyè·å–ä¸Šè¯æ·±è¯çš„è‚¡ç¥¨ä»£ç 
        sh_sz_codes = daily_quarterly['code'].unique()
        print(f"ä¸Šè¯æ·±è¯è‚¡ç¥¨æ•°é‡: {len(sh_sz_codes)}")
        
        # 3. ç­›é€‰è‚¡ä¸œæ•°æ®ï¼Œåªä¿ç•™ä¸Šè¯æ·±è¯çš„æŒè‚¡
        df_filtered = df_holdings_normalized[df_holdings_normalized['ts_code'].isin(sh_sz_codes)].copy()
        print(f"ç­›é€‰åè‚¡ä¸œè®°å½•æ•°: {len(df_filtered)} (åŸè®°å½•æ•°: {len(df_holdings)})")
        
        # 4. è®¡ç®—æ¯ä¸ªè‚¡ä¸œçš„æ€»æŒè‚¡è§„æ¨¡ï¼ˆä½¿ç”¨20220630ï¼‰
        recent_date = "2022-06-30"
        print(recent_date)
        recent_holdings = df_filtered[df_filtered['end_date'] == recent_date]
        
        holder_size = recent_holdings.groupby('holder_name')['hold_amount'].sum().sort_values(ascending=False)
        print(f"è‚¡ä¸œæ€»æ•°: {len(holder_size)}")
        print(f"æœ€å¤§æŒè‚¡è‚¡ä¸œ: {holder_size.index[0]} ({holder_size.iloc[0]:,.2f}å…ƒ)")
        print(holder_size[:10])
        
        # 5. é€‰æ‹©å‰Nå¤§è‚¡ä¸œ
        top_holders = holder_size.head(top_n).index
        df_top_holders = df_filtered[df_filtered['holder_name'].isin(top_holders)]
        
        print(f"å‰{top_n}å¤§è‚¡ä¸œè®°å½•æ•°: {len(df_top_holders)}")
        print(f"æ¶‰åŠè‚¡ç¥¨æ•°é‡: {df_top_holders['ts_code'].nunique()}")
        
        return df_top_holders

    def calculate_holder_size_rank(self, df_holdings):
        """
        è®¡ç®—è‚¡ä¸œè§„æ¨¡æ’å
        
        Parameters:
        df_holdings: è‚¡ä¸œæŒè‚¡æ•°æ®
        
        Returns:
        Series: è‚¡ä¸œè§„æ¨¡æ’å
        """
        # ä½¿ç”¨æœ€è¿‘å­£åº¦çš„æŒè‚¡è§„æ¨¡
        recent_date = "2022-06-30"
        recent_holdings = df_holdings[df_holdings['end_date'] == recent_date]
        
        holder_size = recent_holdings.groupby('holder_name')['hold_amount'].sum()
        holder_rank = holder_size.rank(ascending=False, method='min')
        
        return holder_rank

    def normalize_scores_to_normal_distribution(self, scored_data, score_column = 'comprehensive score', mean=50, std=10, negative = 0):
        """
        å°†è¯„åˆ†æŠ•å°„åˆ°æ­£æ€åˆ†å¸ƒ
        
        Parameters:
        scored_data: åŸå§‹è¯„åˆ†æ•°æ®
        mean: ç›®æ ‡åˆ†å¸ƒçš„å‡å€¼
        std: ç›®æ ‡åˆ†å¸ƒçš„æ ‡å‡†å·®
        
        Returns:
        DataFrame: åŒ…å«æ­£æ€åˆ†å¸ƒè¯„åˆ†çš„æ•°æ®
        """
        print("å°†è¯„åˆ†æŠ•å°„åˆ°æ­£æ€åˆ†å¸ƒ...")
        
        normalized_data = scored_data.copy()
        
        # å¯¹ç»¼åˆå¾—åˆ†è¿›è¡Œæ­£æ€åˆ†å¸ƒè½¬æ¢
        if negative == 0:
            comprehensive_scores = normalized_data[score_column]
        else:
            comprehensive_scores = -normalized_data[score_column]
        
        # è®¡ç®—åŸå§‹å¾—åˆ†çš„æ’åç™¾åˆ†ä½
        ranks = comprehensive_scores.rank(method='average')
        percentiles = ranks / (len(ranks) + 1)  # ä½¿ç”¨(len+1)é¿å…100%åˆ†ä½
        
        # å°†ç™¾åˆ†ä½æ˜ å°„åˆ°æ­£æ€åˆ†å¸ƒ
        normal_scores = stats.norm.ppf(percentiles, loc=mean, scale=std)
        
        # å¤„ç†æç«¯å€¼ï¼ˆppfå¯èƒ½äº§ç”Ÿinfï¼‰
        normal_scores = np.clip(normal_scores, mean - 4*std, mean + 4*std)
        
        normalized_data['normalized_score'] = normal_scores
        
        # é‡æ–°è®¡ç®—è¯„çº§ï¼ˆåŸºäºæ­£æ€åˆ†å¸ƒå¾—åˆ†ï¼‰
        def get_normalized_rating(score):
            if score >= mean + std:
                return 'ä¼˜ç§€'
            elif score >= mean:
                return 'è‰¯å¥½'
            elif score >= mean - std:
                return 'è¾ƒå·®'
            else:
                return 'å¾ˆå·®'
        
        normalized_data['normalized_rating'] = normalized_data['normalized_score'].apply(get_normalized_rating)
        
        return normalized_data

    def plot_score_distribution_comparison(self, scored_data, normalized_data):
        """
        ç»˜åˆ¶åŸå§‹è¯„åˆ†å’Œæ­£æ€åˆ†å¸ƒè¯„åˆ†çš„å¯¹æ¯”å›¾
        """
        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
        
        # 1. åŸå§‹å¾—åˆ†åˆ†å¸ƒ
        ax1.hist(scored_data['comprehensive_score'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        ax1.set_title('åŸå§‹ç»¼åˆå¾—åˆ†åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax1.set_xlabel('åŸå§‹å¾—åˆ†')
        ax1.set_ylabel('è‚¡ä¸œæ•°é‡')
        ax1.axvline(scored_data['comprehensive_score'].mean(), color='red', linestyle='--', 
                    label=f'å‡å€¼: {scored_data["comprehensive_score"].mean():.1f}')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. æ­£æ€åˆ†å¸ƒå¾—åˆ†
        ax2.hist(normalized_data['normalized_score'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
        ax2.set_title('æ­£æ€åˆ†å¸ƒå¾—åˆ†', fontsize=14, fontweight='bold')
        ax2.set_xlabel('æ­£æ€åˆ†å¸ƒå¾—åˆ†')
        ax2.set_ylabel('è‚¡ä¸œæ•°é‡')
        ax2.axvline(50, color='red', linestyle='--', label='å‡å€¼: 50')
        ax2.axvline(40, color='orange', linestyle=':', label='Â±1æ ‡å‡†å·®')
        ax2.axvline(60, color='orange', linestyle=':')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. è¯„çº§åˆ†å¸ƒå¯¹æ¯”
        original_ratings = scored_data['rating'].value_counts()
        normalized_ratings = normalized_data['normalized_rating'].value_counts()
        
        x = np.arange(len(original_ratings))
        width = 0.35
        
        ax3.bar(x - width/2, original_ratings.values, width, label='åŸå§‹è¯„çº§', alpha=0.7)
        ax3.bar(x + width/2, normalized_ratings.values, width, label='æ­£æ€åˆ†å¸ƒè¯„çº§', alpha=0.7)
        
        ax3.set_title('è¯„çº§åˆ†å¸ƒå¯¹æ¯”', fontsize=14, fontweight='bold')
        ax3.set_xlabel('è¯„çº§')
        ax3.set_ylabel('è‚¡ä¸œæ•°é‡')
        ax3.set_xticks(x)
        ax3.set_xticklabels(original_ratings.index, rotation=45)
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        return fig

    def calculate_portfolio_growth(self, df_holdings):
        """
        è®¡ç®—æŠ•èµ„ç»„åˆå¢é•¿æŒ‡æ ‡
        
        Parameters:
        df_holdings: è‚¡ä¸œæŒè‚¡æ•°æ®ï¼ˆéœ€åŒ…å«end_date, holder_name, hold_amountï¼‰
        
        Returns:
        DataFrame: ç»„åˆå¢é•¿æŒ‡æ ‡
        """
        print("è®¡ç®—æŠ•èµ„ç»„åˆå¢é•¿æŒ‡æ ‡...")
        
        # æŒ‰è‚¡ä¸œå’Œæ—¥æœŸæ±‡æ€»æ€»æŒä»“é‡‘é¢
        portfolio_value = df_holdings.groupby(['holder_name', 'end_date']).agg({
            'hold_amount': 'sum',
            'ts_code': 'nunique'  # æŒè‚¡æ•°é‡
        }).reset_index()
        
        portfolio_value['end_date'] = pd.to_datetime(portfolio_value['end_date'])
        portfolio_value = portfolio_value.sort_values(['holder_name', 'end_date'])
        
        growth_metrics = []
        
        for holder in portfolio_value['holder_name'].unique():
            holder_data = portfolio_value[portfolio_value['holder_name'] == holder]
            
            if len(holder_data) < 2:  # è‡³å°‘éœ€è¦2ä¸ªæ—¶é—´ç‚¹
                continue
            
            # è®¡ç®—ç»„åˆä»·å€¼å¢é•¿
            first_value = holder_data['hold_amount'].iloc[0]
            last_value = holder_data['hold_amount'].iloc[-1]
            total_growth = (last_value - first_value) / first_value if first_value > 0 else 0
            
            # è®¡ç®—å­£åº¦å¢é•¿ç‡
            holder_data = holder_data.copy()
            holder_data['quarter_growth'] = holder_data['hold_amount'].pct_change()
            avg_quarter_growth = holder_data['quarter_growth'].mean()
            
            # å¢é•¿ç¨³å®šæ€§
            growth_std = holder_data['quarter_growth'].std()
            growth_stability = 1 / (1 + growth_std) if not pd.isna(growth_std) else 0
            
            # æŒç»­å¢é•¿å­£åº¦æ•°
            positive_quarters = (holder_data['quarter_growth'] > 0).sum()
            total_quarters = len(holder_data) - 1  # å‡å»ç¬¬ä¸€ä¸ªå­£åº¦ï¼ˆæ— å¢é•¿ç‡ï¼‰
            growth_consistency = positive_quarters / total_quarters if total_quarters > 0 else 0
            
            growth_metrics.append({
                'holder_name': holder,
                'total_growth': total_growth,
                'avg_quarter_growth': avg_quarter_growth,
                'growth_stability': growth_stability,
                'growth_consistency': growth_consistency,
                'start_value': first_value,
                'end_value': last_value,
                'analysis_quarters': len(holder_data),
                'positive_quarters': positive_quarters
            })
        
        return pd.DataFrame(growth_metrics)
    
    def calculate_investment_stability(self, df_holdings):
        """
        è®¡ç®—æŠ•èµ„ç¨³å®šæ€§æŒ‡æ ‡
        
        Parameters:
        df_holdings: è‚¡ä¸œæŒè‚¡æ•°æ®
        
        Returns:
        DataFrame: ç¨³å®šæ€§æŒ‡æ ‡
        """
        print("è®¡ç®—æŠ•èµ„ç¨³å®šæ€§æŒ‡æ ‡...")
        
        stability_metrics = []
        
        for holder in df_holdings['holder_name'].unique():
            holder_data = df_holdings[df_holdings['holder_name'] == holder]
            
            # æŒè‚¡æ•°é‡ç¨³å®šæ€§
            stock_count_by_date = holder_data.groupby('end_date')['ts_code'].nunique()
            stock_count_stability = 1 / (1 + stock_count_by_date.std()) if len(stock_count_by_date) > 1 else 0
            
            # æŒä»“é›†ä¸­åº¦ç¨³å®šæ€§
            concentration_by_date = []
            for date in holder_data['end_date'].unique():
                date_data = holder_data[holder_data['end_date'] == date]
                total_amount = date_data['hold_amount'].sum()
                if total_amount > 0:
                    # èµ«èŠ¬è¾¾å°”æŒ‡æ•°
                    hhi = ((date_data['hold_amount'] / total_amount) ** 2).sum()
                    concentration_by_date.append(hhi)
            
            concentration_stability = 1 / (1 + np.std(concentration_by_date)) if concentration_by_date else 0
            
            # æŠ•èµ„æœŸé™ï¼ˆè‚¡ç¥¨å¹³å‡æŒæœ‰æœŸï¼‰
            holding_periods = self.calculate_avg_holding_period(holder_data)
            
            stability_metrics.append({
                'holder_name': holder,
                'stock_count_stability': stock_count_stability,
                'concentration_stability': concentration_stability,
                'avg_holding_period': holding_periods.get('avg_quarters', 0),
                'turnover_rate': holding_periods.get('turnover_rate', 0)
            })
        
        return pd.DataFrame(stability_metrics)
    
    def calculate_avg_holding_period(self, holder_data):
        """
        è®¡ç®—å¹³å‡æŒæœ‰æœŸå’Œæ¢æ‰‹ç‡
        
        Parameters:
        holder_data: å•ä¸ªè‚¡ä¸œçš„æ•°æ®
        
        Returns:
        dict: æŒæœ‰æœŸæŒ‡æ ‡
        """
        # æŒ‰è‚¡ç¥¨åˆ†ææŒæœ‰æœŸ
        stock_holding = []
        
        for ts_code in holder_data['ts_code'].unique():
            stock_data = holder_data[holder_data['ts_code'] == ts_code].copy()
            stock_data['end_date'] = pd.to_datetime(stock_data['end_date'])
            stock_data = stock_data.sort_values('end_date')
            
            if len(stock_data) > 1:
                holding_quarters = len(stock_data)
                stock_holding.append(holding_quarters)
        
        if stock_holding:
            avg_quarters = np.mean(stock_holding)
            # ç®€åŒ–æ¢æ‰‹ç‡è®¡ç®—ï¼š1/å¹³å‡æŒæœ‰æœŸ
            turnover_rate = 1 / avg_quarters if avg_quarters > 0 else 0
        else:
            avg_quarters = 0
            turnover_rate = 0
        
        return {
            'avg_quarters': avg_quarters,
            'turnover_rate': turnover_rate
        }
    
    def calculate_concentration_metrics(self, df_holdings):
        """
        è®¡ç®—é›†ä¸­åº¦æŒ‡æ ‡
        
        Parameters:
        df_holdings: è‚¡ä¸œæŒè‚¡æ•°æ®
        
        Returns:
        DataFrame: é›†ä¸­åº¦æŒ‡æ ‡
        """
        print("è®¡ç®—é›†ä¸­åº¦æŒ‡æ ‡...")
        
        concentration_metrics = []
        
        for holder in df_holdings['holder_name'].unique():
            holder_data = df_holdings[df_holdings['holder_name'] == holder]
            
            # ä½¿ç”¨æœ€è¿‘å­£åº¦çš„æ•°æ®
            recent_date = '2022-06-30'
            recent_data = holder_data[holder_data['end_date'] == recent_date]
            
            if len(recent_data) == 0:
                continue
            
            total_amount = recent_data['hold_amount'].sum()
            
            if total_amount > 0:
                # èµ«èŠ¬è¾¾å°”æŒ‡æ•°
                weights = recent_data['hold_amount'] / total_amount
                hhi_index = (weights ** 2).sum()
                
                # å‰ä¸‰å¤§æŒä»“å æ¯”
                top3_weight = weights.nlargest(3).sum()
                
                # æŒè‚¡æ•°é‡
                stock_count = len(recent_data)
                
                # é›†ä¸­åº¦è¯„åˆ†ï¼ˆé€‚ä¸­çš„é›†ä¸­åº¦æ›´å¥½ï¼‰
                # HHIåœ¨0.1-0.25ä¹‹é—´è®¤ä¸ºé€‚ä¸­
                if hhi_index < 0.1:
                    concentration_score = hhi_index / 0.1  # è¿‡äºåˆ†æ•£
                elif hhi_index > 0.25:
                    concentration_score = 1 - (hhi_index - 0.25) / 0.75  # è¿‡äºé›†ä¸­
                else:
                    concentration_score = 1.0  # é€‚ä¸­
                
                concentration_metrics.append({
                    'holder_name': holder,
                    'hhi_index': hhi_index,
                    'top3_concentration': top3_weight,
                    'stock_count': stock_count,
                    'concentration_score': max(0, min(1, concentration_score))  # é™åˆ¶åœ¨0-1ä¹‹é—´
                })
        
        return pd.DataFrame(concentration_metrics)
    
    def calculate_investment_consistency(self, df_holdings, industry_data=None):
        """
        è®¡ç®—æŠ•èµ„ä¸€è‡´æ€§æŒ‡æ ‡
        
        Parameters:
        df_holdings: è‚¡ä¸œæŒè‚¡æ•°æ®
        industry_data: è¡Œä¸šæ•°æ®ï¼ˆå¯é€‰ï¼‰
        
        Returns:
        DataFrame: ä¸€è‡´æ€§æŒ‡æ ‡
        """
        print("è®¡ç®—æŠ•èµ„ä¸€è‡´æ€§æŒ‡æ ‡...")
        
        consistency_metrics = []
        
        for holder in df_holdings['holder_name'].unique():
            holder_data = df_holdings[df_holdings['holder_name'] == holder]
            holder_data = holder_data.sort_values('end_date')
            
            dates = holder_data['end_date'].unique()
            if len(dates) < 2:
                continue
            
            # 1. æŒè‚¡è¿ç»­æ€§
            continuous_quarters = 0
            max_continuous = 0
            current_continuous = 0
            
            for i in range(len(dates)):
                if i == 0:
                    current_continuous = 1
                else:
                    prev_date = pd.to_datetime(dates[i-1])
                    curr_date = pd.to_datetime(dates[i])
                    quarter_gap = (curr_date.year - prev_date.year) * 4 + (curr_date.month - prev_date.month) / 3
                    
                    if quarter_gap <= 1.5:  # å…è®¸ä¸€ä¸ªå­£åº¦çš„é—´éš”
                        current_continuous += 1
                    else:
                        max_continuous = max(max_continuous, current_continuous)
                        current_continuous = 1
            
            max_continuous = max(max_continuous, current_continuous)
            continuity_score = max_continuous / len(dates) if len(dates) > 0 else 0
            
            # 2. è§„æ¨¡ç¨³å®šæ€§
            portfolio_sizes = holder_data.groupby('end_date')['hold_amount'].sum()
            size_stability = 1 / (1 + portfolio_sizes.std() / portfolio_sizes.mean()) if portfolio_sizes.mean() > 0 else 0
            
            consistency_metrics.append({
                'holder_name': holder,
                'continuity_score': continuity_score,
                'size_stability': size_stability,
                'total_quarters': len(dates),
                'max_continuous_quarters': max_continuous
            })
        
        return pd.DataFrame(consistency_metrics)
    
    def build_ability_score(self, growth_df, stability_df, concentration_df, consistency_df):
        """
        å·²åºŸå¼ƒï¼šè¯·ä½¿ç”¨ run_complete_analysis_v2 çš„è¯„åˆ†ä¸è¾“å‡ºæµç¨‹ã€‚
        æ­¤æ–¹æ³•ä¿ç•™ä¸ºç©ºï¼Œä»¥é¿å…ä¸æ–°ç‰ˆæµç¨‹å†²çªã€‚
        """
        print("[Deprecated] build_ability_score å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ run_complete_analysis_v2ã€‚")
        return None
    
    def plot_portfolio_growth_comparison(self, df_holdings, scored_data, top_stars=5, top_problems=3):
        """
        å·²åºŸå¼ƒï¼šæ–°ç‰ˆæµç¨‹ä¸å†ä½¿ç”¨è¯¥ç»˜å›¾æ–¹æ³•ã€‚
        ä¿ç•™ç©ºå®ç°ä»¥å…¼å®¹æ—§è°ƒç”¨ã€‚
        """
        print("[Deprecated] plot_portfolio_growth_comparison å·²åºŸå¼ƒã€‚")
        return None
    
    def _plot_growth_curves(self, ax, portfolio_values, shareholders, title):
        """
        å·²åºŸå¼ƒçš„å†…éƒ¨ç»˜å›¾å‡½æ•°ã€‚
        """
        return
    
    def run_complete_analysis_v2(self, df_holdings, daily_quarterly, industry_data=None, 
                           top_holders=200, min_quarters=8):
        """
        æ”¹è¿›ç‰ˆçš„å®Œæ•´åˆ†ææµç¨‹
        
        Parameters:
        df_holdings: è‚¡ä¸œæŒè‚¡æ•°æ®
        daily_quarterly: å­£åº¦è‚¡ä»·æ•°æ®ï¼ˆç”¨äºç­›é€‰ä¸Šè¯æ·±è¯ï¼‰
        industry_data: è¡Œä¸šæ•°æ®
        top_holders: å‰Nå¤§è‚¡ä¸œ
        min_quarters: æœ€å°åˆ†æå­£åº¦æ•°
        """
        print("=== å¼€å§‹æ”¹è¿›ç‰ˆè‚¡ä¸œæŠ•èµ„èƒ½åŠ›åˆ†æ ===")
        
        try:
            # 1. ç­›é€‰ä¸Šè¯æ·±è¯æ•°æ®å¹¶é€‰æ‹©å‰Nå¤§è‚¡ä¸œ
            df_filtered = self.filter_exchanges_and_top_holders(
                df_holdings, daily_quarterly, top_holders
            )
            
            # 2. è¿›ä¸€æ­¥ç­›é€‰æœ‰è¶³å¤Ÿæ•°æ®çš„è‚¡ä¸œ
            holder_quarters = df_filtered.groupby('holder_name')['end_date'].nunique()
            qualified_holders = holder_quarters[holder_quarters >= min_quarters].index
            df_qualified = df_filtered[df_filtered['holder_name'].isin(qualified_holders)]
            
            print(f"æœ€ç»ˆåˆ†æ {len(qualified_holders)} ä¸ªç¬¦åˆæ¡ä»¶çš„è‚¡ä¸œ...")
            
            # 3. è®¡ç®—å„é¡¹æŒ‡æ ‡ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼‰
            growth_metrics = self.calculate_portfolio_growth(df_qualified)
            growth_metrics = self.normalize_scores_to_normal_distribution(growth_metrics, score_column = 'avg_quarter_growth')
            growth_metrics.to_csv('growth_metrics.csv', encoding='gbk')
            growth_metrics = growth_metrics[['holder_name', 'avg_quarter_growth', 'normalized_score']].rename(columns={'normalized_score': 'growth_score'})

            stability_metrics = self.calculate_investment_stability(df_qualified)
            stability_metrics = self.normalize_scores_to_normal_distribution(stability_metrics, score_column = 'turnover_rate')
            stability_metrics.to_csv('stability_metrics.csv', encoding='gbk')
            stability_metrics = stability_metrics[['holder_name', 'normalized_score']].rename(columns={'normalized_score': 'stability_score'})
            
            concentration_metrics = self.calculate_concentration_metrics(df_qualified)
            concentration_metrics = self.normalize_scores_to_normal_distribution(concentration_metrics, score_column = 'concentration_score')
            concentration_metrics.to_csv('concentration_metrics.csv', encoding='gbk')
            concentration_metrics = concentration_metrics[['holder_name', 'normalized_score']].rename(columns={'normalized_score': 'concentration_score'})
            
            consistency_metrics = self.calculate_investment_consistency(df_qualified, industry_data)
            consistency_metrics = self.normalize_scores_to_normal_distribution(consistency_metrics, score_column = 'size_stability', negative = 1)
            consistency_metrics.to_csv('consistency_metrics.csv', encoding='gbk')
            consistency_metrics = consistency_metrics[['holder_name', 'normalized_score']].rename(columns={'normalized_score': 'consistency_score'})
            
            
            # 4. æ„å»ºç»¼åˆè¯„åˆ†
            scored_df = growth_metrics.merge(stability_metrics, on='holder_name', how='inner')
            scored_df = scored_df.merge(concentration_metrics, on='holder_name', how='inner')
            scored_df = scored_df.merge(consistency_metrics, on='holder_name', how='inner')
            scored_df['score'] = 0.5*scored_df['growth_score'] + 0.25*scored_df['stability_score'] + 0.1*scored_df['concentration_score'] + 0.15*scored_df['consistency_score']
            scored_df.sort_values(by='score', ascending=False, inplace=True)
            print(scored_df)
            scored_df.to_csv('scored_data.csv', encoding='gbk')
            growth_metrics.set_index('holder_name', inplace=True)


            
            # 5. è¯†åˆ«æ˜æ˜Ÿå’Œé—®é¢˜è‚¡ä¸œï¼ˆæ­£æ•°/å€’æ•°å‰10ï¼‰ï¼Œä»¥åŠè¯„åˆ†
            star_shareholders = scored_df.iloc[:10]
            problem_shareholders = scored_df.iloc[-10:]
            scored_df['rating'] = pd.cut(scored_df['score'], bins=[-float('inf'), 0.2, 0.5, 0.8, float('inf')],
                                        labels=['é—®é¢˜', 'ä¸€èˆ¬', 'è‰¯å¥½', 'ä¼˜ç§€'])
            
            classification_result = {
                'star_shareholders': star_shareholders,
                'problem_shareholders': problem_shareholders,
                'rating_distribution': scored_df['rating'].value_counts(),
                'original_rating_distribution': scored_df['rating'].value_counts()
            }
            # 7. æ–°ç‰ˆè¾“å‡ºï¼šä½¿ç”¨ç»Ÿä¸€çš„æ–°æŠ¥å‘Šä¸ä¿å­˜å‡½æ•°
            # æ³¨é‡Šæ—§ç‰ˆè¾“å‡ºå‡½æ•°ï¼ˆgenerate_enhanced_reportï¼‰ï¼Œæ”¹ç”¨æ›´æ¸…æ™°çš„æ–°ç‰ˆè¾“å‡º
            # self.generate_enhanced_report(scored_df, classification_result, growth_metrics)

            self.output_new_report(
                scored_df=scored_df,
                classification_result=classification_result,
                growth_metrics=growth_metrics,
                stability_metrics=stability_metrics,
                concentration_metrics=concentration_metrics,
                consistency_metrics=consistency_metrics,
            )

            # å¯é€‰ï¼šç»Ÿä¸€ä¿å­˜æ‰€æœ‰ç»“æœCSVåˆ° outputs/ ç›®å½•
            self.save_results(
                scored_df=scored_df,
                growth_metrics=growth_metrics,
                stability_metrics=stability_metrics,
                concentration_metrics=concentration_metrics,
                consistency_metrics=consistency_metrics,
                directory='outputs'
            )
            
            print("=== æ”¹è¿›ç‰ˆåˆ†æå®Œæˆ ===")
            
            return {
                'growth_metrics': growth_metrics,
                'stability_metrics': stability_metrics,
                'concentration_metrics': concentration_metrics,
                'consistency_metrics': consistency_metrics,
                'scored_data': scored_df,
                'classification_result': classification_result,
                'df_filtered': df_filtered
            }
            
        except Exception as e:
            print(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def generate_enhanced_report(self, normalized_data, classification_result, growth_metrics):
        """
        å·²åºŸå¼ƒï¼šæ–°ç‰ˆå°†ä½¿ç”¨ output_new_report è¾“å‡ºã€‚
        ä¿ç•™ç©ºå®ç°ä»¥é¿å…æ—§è°ƒç”¨æŠ¥é”™ã€‚
        """
        print("[Deprecated] generate_enhanced_report å·²åºŸå¼ƒã€‚")
        return None

    def get_expected_normal_percentage(self, rating):
        """è·å–ç†è®ºæ­£æ€åˆ†å¸ƒç™¾åˆ†æ¯”"""
        expected_percentages = {
            'æ˜æ˜Ÿè‚¡ä¸œ': 15.9,  # å‡å€¼+1æ ‡å‡†å·®ä»¥ä¸Š
            'ä¼˜ç§€è‚¡ä¸œ': 34.1,  # å‡å€¼åˆ°å‡å€¼+1æ ‡å‡†å·®
            'ä¸€èˆ¬è‚¡ä¸œ': 34.1,  # å‡å€¼-1æ ‡å‡†å·®åˆ°å‡å€¼
            'å¾…è§‚å¯Ÿè‚¡ä¸œ': 13.6, # å‡å€¼-2æ ‡å‡†å·®åˆ°å‡å€¼-1æ ‡å‡†å·®
            'é—®é¢˜è‚¡ä¸œ': 2.3    # å‡å€¼-2æ ‡å‡†å·®ä»¥ä¸‹
        }
        return expected_percentages.get(rating, 0)

    def identify_main_issue(self, holder_data):
        """è¯†åˆ«ä¸»è¦é—®é¢˜"""
        issues = []
        
        if holder_data['total_growth'] < 0:
            issues.append("è´Ÿå¢é•¿")
        if holder_data['hhi_index'] > 0.3:
            issues.append("è¿‡åº¦é›†ä¸­")
        elif holder_data['hhi_index'] < 0.05:
            issues.append("è¿‡åº¦åˆ†æ•£")
        if holder_data['turnover_rate'] > 0.4:
            issues.append("é«˜æ¢æ‰‹")
        if holder_data['continuity_score'] < 0.5:
            issues.append("ä½è¿ç»­æ€§")
        
        return "ã€".join(issues) if issues else "å¤šç»´åº¦è¡¨ç°ä¸ä½³"

    # ===================== æ–°ç‰ˆç»Ÿä¸€è¾“å‡ºå‡½æ•° =====================
    def output_new_report(self, scored_df, classification_result, 
                          growth_metrics, stability_metrics, 
                          concentration_metrics, consistency_metrics):
        """
        æ–°ç‰ˆç»Ÿä¸€è¾“å‡ºï¼šæŒ‰ç…§ run_complete_analysis_v2 çš„æ€è·¯ï¼Œè¾“å‡ºæ ¸å¿ƒç»“æœã€‚
        - æ¦‚è§ˆç»Ÿè®¡ï¼ˆå‡å€¼/æ ‡å‡†å·®/åˆ†ä½ï¼‰
        - TOP/Bottom æ’å
        - å…³é”®æŒ‡æ ‡å¿«ç…§
        """
        print(f"\n{'='*80}")
        print("ğŸ¯ è‚¡ä¸œæŠ•èµ„èƒ½åŠ›ç»¼åˆæŠ¥å‘Šï¼ˆæ–°ç‰ˆè¾“å‡ºï¼‰")
        print(f"{'='*80}")

        # æ¦‚è§ˆç»Ÿè®¡
        print("\næ¦‚è§ˆç»Ÿè®¡:")
        print(f"â€¢ è‚¡ä¸œæ•°é‡: {len(scored_df)}")
        print(f"â€¢ å¾—åˆ†å‡å€¼: {scored_df['score'].mean():.2f}")
        print(f"â€¢ å¾—åˆ†æ ‡å‡†å·®: {scored_df['score'].std():.2f}")
        print(f"â€¢ å¾—åˆ†åˆ†ä½(20/50/80): {scored_df['score'].quantile(0.2):.2f} / {scored_df['score'].median():.2f} / {scored_df['score'].quantile(0.8):.2f}")

        # TOP/Bottom æ’å
        top_n = 10
        print(f"\nTOP{top_n} æ˜æ˜Ÿè‚¡ä¸œ:")
        for i, (_, holder) in enumerate(scored_df.nlargest(top_n, 'score').iterrows(), 1):
            avg_growth = growth_metrics.loc[holder['holder_name'], 'avg_quarter_growth'] if holder['holder_name'] in growth_metrics.index else np.nan
            print(f"{i:2d}. {holder['holder_name']:<25} | å¾—åˆ†: {holder['score']:5.1f} | å¹³å‡æ¶¨å¹…: {avg_growth:.2f}")

        print(f"\nBottom{top_n} é—®é¢˜è‚¡ä¸œ:")
        for i, (_, holder) in enumerate(scored_df.nsmallest(top_n, 'score').iterrows(), 1):
            avg_growth = growth_metrics.loc[holder['holder_name'], 'avg_quarter_growth'] if holder['holder_name'] in growth_metrics.index else np.nan
            print(f"{i:2d}. {holder['holder_name']:<25} | å¾—åˆ†: {holder['score']:5.1f} | å¹³å‡æ¶¨å¹…: {avg_growth:.2f}")

        # è¯„çº§åˆ†å¸ƒ
        print("\nè¯„çº§åˆ†å¸ƒ:")
        print(scored_df['rating'].value_counts().to_string())

        # æŒ‡æ ‡å¿«ç…§
        def snap(df, name):
            print(f"\n{name} æŒ‡æ ‡å¿«ç…§:")
            print(df.head(10).to_string(index=False))
        snap(growth_metrics.reset_index(), 'å¢é•¿')
        snap(stability_metrics, 'ç¨³å®šæ€§')
        snap(concentration_metrics, 'é›†ä¸­åº¦')
        snap(consistency_metrics, 'ä¸€è‡´æ€§')

        print(f"\n{'='*80}")

    def save_results(self, scored_df, growth_metrics, stability_metrics, 
                     concentration_metrics, consistency_metrics, directory='outputs'):
        """
        å°†æ‰€æœ‰å…³é”®ç»“æœç»Ÿä¸€ä¿å­˜ä¸º CSVï¼Œç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»ºã€‚
        """
        import os
        os.makedirs(directory, exist_ok=True)
        paths = {
            'scored_data.csv': scored_df,
            'growth_metrics.csv': growth_metrics.reset_index(),
            'stability_metrics.csv': stability_metrics,
            'concentration_metrics.csv': concentration_metrics,
            'consistency_metrics.csv': consistency_metrics,
        }
        for fname, df in paths.items():
            try:
                df.to_csv(os.path.join(directory, fname), index=False, encoding='utf-8-sig')
            except Exception:
                # å›é€€åˆ° gbkï¼Œé¿å…éƒ¨åˆ†ä¸­æ–‡è·¯å¾„/å†…å®¹é—®é¢˜
                df.to_csv(os.path.join(directory, fname), index=False, encoding='gbk')
        print(f"âœ… å·²ä¿å­˜ç»“æœåˆ°ç›®å½•: {directory}")

# ä¾¿æ·å‡½æ•°
def create_amount_analyzer():
    """åˆ›å»ºåŸºäºæŒè‚¡é‡‘é¢çš„åˆ†æå™¨å®ä¾‹"""
    return ShareholderAmountAnalyzer()